{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import nrrd\n",
    "import pytorch_lightning as pl\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.transforms import Compose, Lambda, RandSpatialCrop, RandRotate90, ToTensor\n",
    "from monai.networks.nets import AutoEncoder\n",
    "#from monai.losses import DiceLoss\n",
    "import tensorflow as tf\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "#Using AutoEncoder instead of UNet to avoid skip connections \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class SlicePlotter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def plot_slices(self, original_slice, reconstruction_slice, title):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_slice, cmap='gray')\n",
    "        plt.title(f'Original {title} Slice')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(reconstruction_slice, cmap='gray')\n",
    "        plt.title(f'Reconstructed {title} Slice')\n",
    "        plt.show()\n",
    "\n",
    "class VolumePlotter:\n",
    "    def __init__(self):\n",
    "        self.color_map = np.array([\n",
    "            [0, 0, 0, 0],      # Transparent for background (0)\n",
    "            [255, 0, 0, 255],  # Red for arteries (1)\n",
    "            [0, 0, 255, 255]   # Blue for veins (2)\n",
    "        ], dtype=np.uint8)\n",
    "        self.downsample_factor = 2\n",
    "\n",
    "    def plot_volumes(self, original_volume, reconstruction_volume, title):\n",
    "        # Downsample original volume\n",
    "        original_volume_downsampled = original_volume[::self.downsample_factor, \n",
    "                                                       ::self.downsample_factor, \n",
    "                                                       ::self.downsample_factor]\n",
    "\n",
    "        # Downsample reconstructed volume\n",
    "        reconstruction_volume_downsampled = reconstruction_volume[::self.downsample_factor, \n",
    "                                                                   ::self.downsample_factor, \n",
    "                                                                   ::self.downsample_factor]\n",
    "\n",
    "        # Downsample color map along the first axis to match the number of unique values in the downsampled volume\n",
    "        color_map_downsampled = self.color_map[:len(np.unique(original_volume_downsampled))]\n",
    "\n",
    "        # Plot original and reconstructed volumes with titles using Matplotlib\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Plot original volume with assigned colors and no edge color\n",
    "        ax1 = fig.add_subplot(121, projection='3d')\n",
    "        ax1.set_title(f'Original {title} Volume')\n",
    "\n",
    "        # Define colors for each voxel value in the original volume using the downsampled color map\n",
    "        original_colors = np.take(color_map_downsampled, original_volume_downsampled, axis=0) / 255.0\n",
    "        ax1.voxels(original_volume_downsampled, facecolors=original_colors)\n",
    "\n",
    "        # Plot reconstructed volume with assigned colors and no edge color\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "        ax2.set_title(f'Reconstructed {title} Volume')\n",
    "\n",
    "        # Define colors for each voxel value in the reconstructed volume using the downsampled color map\n",
    "        reconstruction_colors = np.take(color_map_downsampled, reconstruction_volume_downsampled, axis=0) / 255.0\n",
    "        ax2.voxels(reconstruction_volume_downsampled, facecolors=reconstruction_colors)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "class AutoEncoderModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.autoencoder = AutoEncoder(\n",
    "            spatial_dims=3, \n",
    "            in_channels=1, \n",
    "            out_channels=3,  # Output channels set to 3\n",
    "            channels=(16, 32, 64, 128, 32), \n",
    "            strides=(2, 2, 2, 2, 2), \n",
    "            kernel_size=3, \n",
    "            num_res_units=2\n",
    "        )\n",
    "        # Define class weights\n",
    "        class_weights = torch.tensor([0.2, 0.4, 0.4])\n",
    "        self.loss_function = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        self.volume_plotter = VolumePlotter()  # Instantiate VolumePlotter\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.autoencoder(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_hat = self(x)\n",
    "        loss = self.loss_function(x_hat, y.squeeze(1).long())\n",
    "        self.log('train_loss', loss)\n",
    "\n",
    "        if self.current_epoch % 300 == 0 and batch_idx == 0:\n",
    "            original_volume = x[0, 0, :, :, :].detach().cpu().numpy().astype(int)  \n",
    "            reconstruction_volume = np.argmax(x_hat[0,:,:,:,:].detach().cpu().numpy(), axis=0)\n",
    "            self.volume_plotter.plot_volumes(original_volume, reconstruction_volume, 'Train')\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_hat = self(x)\n",
    "        loss = self.loss_function(x_hat, y.squeeze(1).long())\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "        if self.current_epoch % 250 == 0 and batch_idx == 0:\n",
    "            original_volume = x[0, 0, :, :, :].detach().cpu().numpy().astype(int)  \n",
    "            reconstruction_volume = np.argmax(x_hat[0,:,:,:,:].detach().cpu().numpy(), axis=0)\n",
    "            self.volume_plotter.plot_volumes(original_volume, reconstruction_volume, 'Val')\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# Define dataset and data loaders for both training and validation sets\n",
    "train_data_dir = \"./images/TrainFullLabels70\"\n",
    "val_data_dir = \"./images/ValFullLabels30\"\n",
    "\n",
    "transform = Compose([\n",
    "    Lambda(func=lambda x: np.expand_dims(x, 0) if x.ndim == 3 else x),\n",
    "    RandSpatialCrop((256, 256, 256), random_size=False),\n",
    "    RandRotate90(prob=0.5),\n",
    "    ToTensor(dtype=torch.float32)\n",
    "])\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.files = [f for f in os.listdir(data_dir) if f.endswith('.nrrd')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.data_dir, self.files[idx])\n",
    "        data, header = nrrd.read(file_path)\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data, data\n",
    "\n",
    "train_dataset = MyDataset(train_data_dir, transform)\n",
    "val_dataset = MyDataset(val_data_dir, transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# Define a custom callback to plot both training and validation losses\n",
    "\n",
    "class PlotLossCallback(pl.Callback):\n",
    "    def __init__(self, log_dir):\n",
    "        super().__init__()\n",
    "        self.log_dir = log_dir\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        # Clear previous graphs\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        self.writer = SummaryWriter(self.log_dir)\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module, **kwargs):\n",
    "        epoch = trainer.current_epoch\n",
    "        train_loss = trainer.callback_metrics['train_loss'].cpu().item()\n",
    "        val_loss = trainer.callback_metrics['val_loss'].cpu().item()\n",
    "\n",
    "        # Write both training and validation loss to the same graph with epoch as global step\n",
    "        self.writer.add_scalars('64C NS Loss', {'training' : train_loss, \n",
    "                                                   'validation' : val_loss }, global_step=epoch +1 )\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        self.writer.close()\n",
    "\n",
    "# Define ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename='/images/Model/model_64channelNS_{epoch}.pth',\n",
    "    save_last=True,\n",
    "    verbose=True,\n",
    "    every_n_epochs=100\n",
    ")\n",
    "\n",
    "#early_stop_callback = pl.callbacks.EarlyStopping(monitor='val_loss', patience=80)\n",
    "#getting rid of early stop callback for now \n",
    "# Define Lightning trainer\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1500,\n",
    "    callbacks=[PlotLossCallback(\"./logs/\"), checkpoint_callback],\n",
    "    profiler='simple')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:579\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    573\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    575\u001b[0m     ckpt_path,\n\u001b[0;32m    576\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    577\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m )\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:962\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:149\u001b[0m, in \u001b[0;36mStrategy.setup\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\pytorch_lightning\\accelerators\\cuda.py:53\u001b[0m, in \u001b[0;36mCUDAAccelerator.setup\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_nvidia_flags(trainer\u001b[38;5;241m.\u001b[39mlocal_rank)\n\u001b[1;32m---> 53\u001b[0m \u001b[43m_clear_cuda_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\lightning_fabric\\accelerators\\cuda.py:381\u001b[0m, in \u001b[0;36m_clear_cuda_memory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    380\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_clearCublasWorkspaces()\n\u001b[1;32m--> 381\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\torch\\cuda\\memory.py:162\u001b[0m, in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize model and start training\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoEncoderModel()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:543\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 543\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:68\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m logger \u001b[38;5;129;01min\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mloggers:\n\u001b[0;32m     67\u001b[0m     logger\u001b[38;5;241m.\u001b[39mfinalize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[0;32m     70\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1009\u001b[0m, in \u001b[0;36mTrainer._teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_teardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and Callback;\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;124;03m    those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1010\u001b[0m     loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_active_loop\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:540\u001b[0m, in \u001b[0;36mStrategy.teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 540\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_io\u001b[38;5;241m.\u001b[39mteardown()\n",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\pytorch_lightning\\accelerators\\cuda.py:82\u001b[0m, in \u001b[0;36mCUDAAccelerator.teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mteardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 82\u001b[0m     \u001b[43m_clear_cuda_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\lightning_fabric\\accelerators\\cuda.py:381\u001b[0m, in \u001b[0;36m_clear_cuda_memory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TORCH_GREATER_EQUAL_2_0 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_clearCublasWorkspaces\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/95668\u001b[39;00m\n\u001b[0;32m    380\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_clearCublasWorkspaces()\n\u001b[1;32m--> 381\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\torch\\cuda\\memory.py:162\u001b[0m, in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and start training\n",
    "model = AutoEncoderModel()\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
