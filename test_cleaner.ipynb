{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m CrossEntropyLoss\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import nrrd\n",
    "import pytorch_lightning as pl\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.transforms import Compose, Lambda, RandSpatialCrop, RandRotate90, ToTensor\n",
    "from monai.networks.nets import UNet\n",
    "#from monai.losses import DiceLoss\n",
    "import tensorflow as tf\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class SlicePlotter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def plot_slices(self, original_slice, reconstruction_slice, title):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_slice, cmap='gray')\n",
    "        plt.title(f'Original {title} Slice')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(reconstruction_slice, cmap='gray')\n",
    "        plt.title(f'Reconstructed {title} Slice')\n",
    "        plt.show()\n",
    "\n",
    "class VolumePlotter:\n",
    "    def __init__(self):\n",
    "        self.color_map = np.array([\n",
    "            [0, 0, 0, 0],      # Transparent for background (0)\n",
    "            [255, 0, 0, 255],  # Red for arteries (1)\n",
    "            [0, 0, 255, 255]   # Blue for veins (2)\n",
    "        ], dtype=np.uint8)\n",
    "        self.downsample_factor = 2\n",
    "\n",
    "    def plot_volumes(self, original_volume, reconstruction_volume, title):\n",
    "        # Downsample original volume\n",
    "        original_volume_downsampled = original_volume[::self.downsample_factor, \n",
    "                                                       ::self.downsample_factor, \n",
    "                                                       ::self.downsample_factor]\n",
    "\n",
    "        # Downsample reconstructed volume\n",
    "        reconstruction_volume_downsampled = reconstruction_volume[::self.downsample_factor, \n",
    "                                                                   ::self.downsample_factor, \n",
    "                                                                   ::self.downsample_factor]\n",
    "\n",
    "        # Downsample color map along the first axis to match the number of unique values in the downsampled volume\n",
    "        color_map_downsampled = self.color_map[:len(np.unique(original_volume_downsampled))]\n",
    "\n",
    "        # Plot original and reconstructed volumes with titles using Matplotlib\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Plot original volume with assigned colors and no edge color\n",
    "        ax1 = fig.add_subplot(121, projection='3d')\n",
    "        ax1.set_title(f'Original {title} Volume')\n",
    "\n",
    "        # Define colors for each voxel value in the original volume using the downsampled color map\n",
    "        original_colors = np.take(color_map_downsampled, original_volume_downsampled, axis=0) / 255.0\n",
    "        ax1.voxels(original_volume_downsampled, facecolors=original_colors)\n",
    "\n",
    "        # Plot reconstructed volume with assigned colors and no edge color\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "        ax2.set_title(f'Reconstructed {title} Volume')\n",
    "\n",
    "        # Define colors for each voxel value in the reconstructed volume using the downsampled color map\n",
    "        reconstruction_colors = np.take(color_map_downsampled, reconstruction_volume_downsampled, axis=0) / 255.0\n",
    "        ax2.voxels(reconstruction_volume_downsampled, facecolors=reconstruction_colors)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "class AutoEncoder(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.unet = UNet(\n",
    "            spatial_dims = 3,\n",
    "            in_channels=1,\n",
    "            out_channels=3,\n",
    "            channels=(16, 32, 64, 128, 64),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2\n",
    "        )\n",
    "        # Define class weights\n",
    "        class_weights = torch.tensor([0.2, 0.4, 0.4])\n",
    "        self.loss_function = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        self.volume_plotter = VolumePlotter()  # Instantiate VolumePlotter\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.unet(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_hat = self.unet(x)\n",
    "        loss = self.loss_function(x_hat, y.squeeze(1).long())\n",
    "        self.log('train_loss', loss)\n",
    "\n",
    "        if self.current_epoch % 250 == 0 and batch_idx == 0:\n",
    "            original_volume = x[0, 0, :, :, :].detach().cpu().numpy().astype(int)  \n",
    "            reconstruction_volume = np.argmax(x_hat[0,:,:,:,:], axis=0)\n",
    "            self.volume_plotter.plot_volumes(original_volume, reconstruction_volume, 'Train')\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_hat = self.unet(x)\n",
    "        loss = self.loss_function(x_hat, y.squeeze(1).long())\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "        if self.current_epoch % 250 == 0 and batch_idx == 0:\n",
    "            original_volume = x[0, 0, :, :, :].detach().cpu().numpy().astype(int)  \n",
    "            reconstruction_volume = np.argmax(x_hat[0,:,:,:,:], axis=0)\n",
    "            self.volume_plotter.plot_volumes(original_volume, reconstruction_volume, 'Val')\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# Define dataset and data loaders for both training and validation sets\n",
    "train_data_dir = \"./images/TrainFullLabels70\"\n",
    "val_data_dir = \"./images/ValFullLabels30\"\n",
    "\n",
    "transform = Compose([\n",
    "    Lambda(func=lambda x: np.expand_dims(x, 0) if x.ndim == 3 else x),\n",
    "    RandSpatialCrop((256, 256, 256), random_size=False),\n",
    "    RandRotate90(prob=0.5),\n",
    "    ToTensor(dtype=torch.float32)\n",
    "])\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.files = [f for f in os.listdir(data_dir) if f.endswith('.nrrd')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.data_dir, self.files[idx])\n",
    "        data, header = nrrd.read(file_path)\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data, data\n",
    "\n",
    "train_dataset = MyDataset(train_data_dir, transform)\n",
    "val_dataset = MyDataset(val_data_dir, transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# Define a custom callback to plot both training and validation losses\n",
    "\n",
    "class PlotLossCallback(pl.Callback):\n",
    "    def __init__(self, log_dir):\n",
    "        super().__init__()\n",
    "        self.log_dir = log_dir\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        # Clear previous graphs\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        self.writer = SummaryWriter(self.log_dir)\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module, **kwargs):\n",
    "        epoch = trainer.current_epoch\n",
    "        train_loss = trainer.callback_metrics['train_loss'].cpu().item()\n",
    "        val_loss = trainer.callback_metrics['val_loss'].cpu().item()\n",
    "\n",
    "        # Write both training and validation loss to the same graph with epoch as global step\n",
    "        self.writer.add_scalars('1 Channel Loss', {'training' : train_loss, \n",
    "                                                   'validation' : val_loss }, global_step=epoch +1 )\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        self.writer.close()\n",
    "\n",
    "# Define ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename='/images/Model/model_1channel_{epoch}.pth',\n",
    "    save_last=True,\n",
    "    verbose=True,\n",
    "    every_n_epochs=100\n",
    ")\n",
    "\n",
    "#early_stop_callback = pl.callbacks.EarlyStopping(monitor='val_loss', patience=80)\n",
    "#getting rid of early stop callback for now \n",
    "# Define Lightning trainer\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1500,\n",
    "    callbacks=[PlotLossCallback(\"./logs/\"), checkpoint_callback],\n",
    "    profiler='simple')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "property 'current_epoch' of 'Trainer' object has no setter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m starting_epoch \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m \u001b[38;5;241m=\u001b[39m starting_epoch\n\u001b[0;32m      7\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model, train_dataloader, val_dataloader)\n",
      "\u001b[1;31mAttributeError\u001b[0m: property 'current_epoch' of 'Trainer' object has no setter"
     ]
    }
   ],
   "source": [
    "# Initialize model and start training\n",
    "model = AutoEncoder().to(device) \n",
    "checkpoint = torch.load(\"./lightning_logs/version_13/checkpoints/model_1channel_epoch1399.ckpt\")\n",
    "starting_epoch = checkpoint['epoch'] + 1\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "trainer.current_epoch = starting_epoch\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#load in model \n",
    "model = AutoEncoder().to(device) \n",
    "model.load_state_dict(torch.load(\"./images/Model/model_1channel.pth\")) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#2factor downsample 3d image graphing\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "test_dir = \"./images/3dTest\"\n",
    "test_data = MyDataset(test_dir, transform)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Define the color map\n",
    "color_map = np.array([\n",
    "    [0, 0, 0, 0],      # Transparent for background (0)\n",
    "    [255, 0, 0, 255],  # Red for arteries (1)\n",
    "    [0, 0, 255, 255]   # Blue for veins (2)\n",
    "], dtype=np.uint8)\n",
    "\n",
    "# Downsampling factor\n",
    "downsample_factor = 2\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, _) in enumerate(test_dataloader):\n",
    "        x, _ = x.to(device), _.to(device)\n",
    "        x_hat = model(x)\n",
    "        \n",
    "        # Reconstruct and display the whole volume from the first test image\n",
    "        original_volume = x[0, 0, :, :, :].detach().cpu().numpy().astype(int)  \n",
    "\n",
    "        # Downsample original volume\n",
    "        original_volume_downsampled = original_volume[::downsample_factor, ::downsample_factor, ::downsample_factor]\n",
    "\n",
    "        reconstruction_volume = np.argmax(x_hat[0,:,:,:,:], axis=0)\n",
    "\n",
    "        # Downsample reconstructed volume\n",
    "        reconstruction_volume_downsampled = reconstruction_volume[::downsample_factor, ::downsample_factor, ::downsample_factor]\n",
    "\n",
    "        # Downsample color map along the first axis to match the number of unique values in the downsampled volume\n",
    "        color_map_downsampled = color_map[:len(np.unique(original_volume_downsampled))]\n",
    "\n",
    "        # Plot original and reconstructed volumes with titles using Matplotlib\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Plot original volume with assigned colors and no edge color\n",
    "        ax1 = fig.add_subplot(121, projection='3d')\n",
    "        ax1.set_title('Original Test Volume')\n",
    "\n",
    "        # Define colors for each voxel value in the original volume using the downsampled color map\n",
    "        original_colors = np.take(color_map_downsampled, original_volume_downsampled, axis=0) / 255.0\n",
    "        ax1.voxels(original_volume_downsampled, facecolors=original_colors)\n",
    "\n",
    "        # Plot reconstructed volume with assigned colors and no edge color\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "        ax2.set_title('Reconstructed Test Volume')\n",
    "\n",
    "        # Define colors for each voxel value in the reconstructed volume using the downsampled color map\n",
    "        reconstruction_colors = np.take(color_map_downsampled, reconstruction_volume_downsampled, axis=0) / 255.0\n",
    "        ax2.voxels(reconstruction_volume_downsampled, facecolors=reconstruction_colors)\n",
    "\n",
    "        plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "#Testing model\n",
    "\n",
    "test_dir = \"./images/Test\"\n",
    "test_data = MyDataset(test_dir, transform)\n",
    "test_dataloader = DataLoader(test_data, batch_size = 1, shuffle= False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x,_) in enumerate(test_dataloader):\n",
    "        x, _ = x.to(device), _.to(device)\n",
    "        x_hat = model(x)\n",
    "        \n",
    "        # Reconstruct and display a single slice from the first test image\n",
    "        original_slice = x[0, 0, :, :, 128].detach().cpu().numpy() \n",
    "        reconstruction_slice = np.argmax(x_hat[0,:,:,:,128], axis=0)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_slice, cmap='gray')\n",
    "        plt.title('Original Test Slice')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(reconstruction_slice, cmap='gray')\n",
    "        plt.title('Reconstructed Test Slice')\n",
    "        plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
