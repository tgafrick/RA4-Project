{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Folder containing the NRRD files\n",
    "folder_path = \"Y:/E-Masks-Analyses-&Vida/77Images&Labels\"\n",
    "train_folder = \"Z:/RA4/train70\"\n",
    "val_folder = \"Z:/RA4/val30\"\n",
    "\n",
    "# Get the list of files in the source folder that match the naming convention\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('_Vx3.nrrd')]\n",
    "\n",
    "# Randomly select 18 files for training\n",
    "train_files = random.sample(files, 18)\n",
    "\n",
    "# Remove the files selected for training from the list\n",
    "remaining_files = [f for f in files if f not in train_files]\n",
    "\n",
    "# Randomly select 8 files for validation from the remaining files\n",
    "val_files = random.sample(remaining_files, 8)\n",
    "\n",
    "# Define a function to copy files from the source folder to the destination folder\n",
    "def copy_files(files, src_folder, dest_folder):\n",
    "    for file in files:\n",
    "        src_file = os.path.join(src_folder, file)\n",
    "        dest_file = os.path.join(dest_folder, file)\n",
    "        shutil.copy(src_file, dest_file)\n",
    "\n",
    "# Copy the selected files to the training and validation folders\n",
    "copy_files(train_files, folder_path, train_folder)\n",
    "copy_files(val_files, folder_path, val_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import nrrd\n",
    "import pytorch_lightning as pl #python -m pip install lightning\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.transforms import Compose, Lambda, RandSpatialCrop, RandRotate90, ToTensor, ScaleIntensityRange\n",
    "from monai.networks.nets import AutoEncoder\n",
    "from monai.losses import DiceCELoss\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.nn as nn\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using AutoEncoder instead of UNet to avoid skip connections \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"gpu\")\n",
    "\n",
    "class SlicePlotter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def plot_slices(self, original_slice, reconstruction_slice, title):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_slice, cmap='gray')\n",
    "        plt.title(f'Original {title} Slice')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(reconstruction_slice, cmap='gray')\n",
    "        plt.title(f'Reconstructed {title} Slice')\n",
    "        plt.show()\n",
    "\n",
    "class VolumePlotter:\n",
    "    def __init__(self):\n",
    "        self.color_map = np.array([\n",
    "            [0, 0, 0, 0],      # Transparent for background (0)\n",
    "            [255, 0, 0, 255],  # Red for arteries (1)\n",
    "            [0, 0, 255, 255]   # Blue for veins (2)\n",
    "        ], dtype=np.uint8)\n",
    "        self.downsample_factor = 2\n",
    "        self.output_dir = \"./images/visualizations\"\n",
    "\n",
    "        # Create directory if it doesn't exist\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def plot_volumes(self, original_volume, reconstruction_volume, title, epoch):\n",
    "        # Downsample original volume\n",
    "        original_volume_downsampled = original_volume[::self.downsample_factor, \n",
    "                                                       ::self.downsample_factor, \n",
    "                                                       ::self.downsample_factor]\n",
    "\n",
    "        # Downsample reconstructed volume\n",
    "        reconstruction_volume_downsampled = reconstruction_volume[::self.downsample_factor, \n",
    "                                                                   ::self.downsample_factor, \n",
    "                                                                   ::self.downsample_factor]\n",
    "\n",
    "        # Downsample color map along the first axis to match the number of unique values in the downsampled volume\n",
    "        color_map_downsampled = self.color_map[:len(np.unique(original_volume_downsampled))]\n",
    "\n",
    "        # Plot original and reconstructed volumes with titles using Matplotlib\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Plot original volume with assigned colors and no edge color\n",
    "        ax1 = fig.add_subplot(121, projection='3d')\n",
    "        ax1.set_title(f'Original {title} Volume')\n",
    "\n",
    "        # Define colors for each voxel value in the original volume using the downsampled color map\n",
    "        original_colors = np.take(color_map_downsampled, original_volume_downsampled, axis=0) / 255.0\n",
    "        ax1.voxels(original_volume_downsampled, facecolors=original_colors)\n",
    "\n",
    "        # Plot reconstructed volume with assigned colors and no edge color\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "        ax2.set_title(f'Reconstructed {title} Volume')\n",
    "\n",
    "        # Define colors for each voxel value in the reconstructed volume using the downsampled color map\n",
    "        reconstruction_colors = np.take(color_map_downsampled, reconstruction_volume_downsampled, axis=0) / 255.0\n",
    "        ax2.voxels(reconstruction_volume_downsampled, facecolors=reconstruction_colors)\n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(os.path.join(self.output_dir, f\"{title}_epoch{epoch}.png\"))\n",
    "        plt.close()  # Close the figure to release resources\n",
    "\n",
    "class AutoEncoderModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.autoencoder = AutoEncoder(\n",
    "            spatial_dims=3, \n",
    "            in_channels=1, \n",
    "            out_channels=3,  # Output channels set to 3\n",
    "            channels=(16, 32, 64, 128, 256), \n",
    "            strides=(2, 2, 2, 2, 2), \n",
    "            kernel_size=3, \n",
    "            num_res_units=2\n",
    "        )\n",
    "        self.loss_function = DiceCELoss(to_onehot_y=True, softmax=True, include_background=False)  # Use DiceCELoss\n",
    "        self.volume_plotter = VolumePlotter()  # Instantiate VolumePlotter\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.autoencoder(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_hat = self(x)\n",
    "        loss = self.loss_function(x_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "\n",
    "        if self.current_epoch % 300 == 0 and batch_idx == 0:\n",
    "            original_volume = x[0, 0, :, :, :].detach().cpu().numpy().astype(int)  \n",
    "            reconstruction_volume = np.argmax(x_hat[0,:,:,:,:].detach().cpu().numpy(), axis=0)\n",
    "            self.volume_plotter.plot_volumes(original_volume, reconstruction_volume, 'Train', self.current_epoch)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_hat = self(x)\n",
    "        loss = self.loss_function(x_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "        if self.current_epoch % 300 == 0 and batch_idx == 0:\n",
    "            original_volume = x[0, 0, :, :, :].detach().cpu().numpy().astype(int)  \n",
    "            reconstruction_volume = np.argmax(x_hat[0,:,:,:,:].detach().cpu().numpy(), axis=0)\n",
    "            self.volume_plotter.plot_volumes(original_volume, reconstruction_volume, 'Val', self.current_epoch)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=100, factor=0.2, verbose=True)\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': {'scheduler': scheduler, 'monitor': 'val_loss', 'interval': 'epoch', 'frequency': 1}}\n",
    "\n",
    "class MyDataset(CacheDataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.files = [f for f in os.listdir(data_dir) if f.endswith('.nrrd')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.data_dir, self.files[idx])\n",
    "        data, header = nrrd.read(file_path)\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data, data\n",
    "\n",
    "# Define a custom callback to plot both training and validation losses\n",
    "class PlotLossCallback(pl.Callback):\n",
    "    def __init__(self, log_dir):\n",
    "        super().__init__()\n",
    "        self.log_dir = log_dir\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        self.writer = SummaryWriter(self.log_dir)\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module, **kwargs):\n",
    "        epoch = trainer.current_epoch\n",
    "        train_loss = trainer.callback_metrics['train_loss'].cpu().item()\n",
    "        val_loss = trainer.callback_metrics['val_loss'].cpu().item()\n",
    "\n",
    "        # Write both training and validation loss to the same graph with epoch as global step\n",
    "        self.writer.add_scalars('64 NS LR2 Loss', {'training': train_loss, 'validation': val_loss}, global_step=epoch + 1)\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        self.writer.close()\n",
    "\n",
    "# Define ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"./images/Model\",\n",
    "    filename='AE_DCE{epoch}.pth',\n",
    "    save_last=True,\n",
    "    verbose=True,\n",
    "    every_n_epochs=200\n",
    ")\n",
    "\n",
    "transform = Compose([\n",
    "    Lambda(func=lambda x: np.expand_dims(x, 0) if x.ndim == 3 else x),\n",
    "    ScaleIntensityRange(a_min=-1310, a_max=3310, b_min=0, b_max=2),\n",
    "    RandSpatialCrop((256, 256, 256), random_size=False),\n",
    "    RandRotate90(prob=0.5),\n",
    "    ToTensor(dtype=torch.float32)\n",
    "])\n",
    "\n",
    "# Define dataset and data loaders for both training and validation sets\n",
    "train_data_dir = \"Z:/RA4/train70\"\n",
    "val_data_dir = \"Z:/RA4/val30\"\n",
    "\n",
    "\n",
    "train_dataset_uc = MyDataset(train_data_dir, transform)\n",
    "val_dataset_uc = MyDataset(val_data_dir, transform)\n",
    "\n",
    "train_dataset = CacheDataset(train_dataset_uc, transform=transform, num_workers=0)\n",
    "val_dataset = CacheDataset(val_dataset_uc, transform=transform, num_workers=0)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "# Define Lightning trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1500,\n",
    "    callbacks=[PlotLossCallback(\"./logs/\"), checkpoint_callback],\n",
    "    profiler='simple'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
