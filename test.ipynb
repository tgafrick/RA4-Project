{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tgafrick\\Documents\\Github\\RA4-Project\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import nrrd\n",
    "import pytorch_lightning as pl\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.transforms import Compose, Lambda, RandSpatialCrop, RandRotate90, ToTensor\n",
    "from monai.networks.nets import UNet\n",
    "#from monai.losses import DiceLoss\n",
    "import tensorflow as tf\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs directory not found.\n",
      "No logs found in ./lightning_logs/.\n",
      "No runs or logs found in ./runs_and_logs/.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "def clear_tensorboard_logs(log_dir):\n",
    "    # Ensure the directory exists\n",
    "    if os.path.exists(log_dir):\n",
    "        # Delete the directory and its contents\n",
    "        shutil.rmtree(log_dir)\n",
    "        print(\"TensorBoard logs cleared successfully.\")\n",
    "    else:\n",
    "        print(\"TensorBoard logs directory not found.\")\n",
    "\n",
    "def clear_logs(logs_dir):\n",
    "    \"\"\"Clear all logs in the specified directory.\"\"\"\n",
    "    try:\n",
    "        shutil.rmtree(logs_dir)\n",
    "        print(f\"All logs in {logs_dir} have been cleared.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No logs found in {logs_dir}.\")\n",
    "def clear_runs_and_logs(logs_dir):\n",
    "    \"\"\"Clear all runs and logs in the specified directory.\"\"\"\n",
    "    try:\n",
    "        shutil.rmtree(logs_dir)\n",
    "        print(f\"All runs and logs in {logs_dir} have been cleared.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No runs or logs found in {logs_dir}.\")\n",
    "\n",
    "# Specify the directory containing all runs and logs\n",
    "runs_and_logs_dir = \"./runs_and_logs/\"\n",
    "log_dir = \"./logs/\"\n",
    "tensorboard_logs_dir = \"./tensorboard_logs/\"\n",
    "lightning_logs_dir = \"./lightning_logs/\"\n",
    "# Clear TensorBoard logs\n",
    "clear_tensorboard_logs(log_dir)\n",
    "clear_logs(lightning_logs_dir)\n",
    "clear_runs_and_logs(runs_and_logs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "class AutoEncoder(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.unet = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=3,  # Update to 3 output channels\n",
    "            channels=(16, 32, 64, 128, 64),  # Trying one channel EXPERIMENT \n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "        )\n",
    "        # Define class weights\n",
    "        class_weights = torch.tensor([0.2, 0.4, 0.4])\n",
    "        self.loss_function = CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.unet(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_hat = self.unet(x)\n",
    "        loss = self.loss_function(x_hat, y.squeeze(1).long())  # Ensure labels are in the range [0, 2]\n",
    "        self.log('train_loss', loss)\n",
    "\n",
    "        # Reconstruct and display a single slice from the first training image every other epoch\n",
    "        if self.current_epoch % 10 == 0 and batch_idx == 0:\n",
    "            original_slice = x[0, 0, :, :, 128].detach().cpu().numpy()  # Select a single slice from the 3D volume\n",
    "            reconstruction_slice = np.argmax(x_hat[0,:,:,:,128], axis=0) # Select a single slice from the 3D reconstruction\n",
    "\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(original_slice, cmap='gray')\n",
    "            plt.title('Original Train Slice')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(reconstruction_slice, cmap='gray')\n",
    "            plt.title('Reconstructed Train Slice')\n",
    "            plt.show()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x_hat = self.unet(x)\n",
    "        loss = self.loss_function(x_hat, y.squeeze(1).long())  # Ensure labels are in the range [0, 2]\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "        # Reconstruct and display a single slice from the first validation image every other epoch\n",
    "        if self.current_epoch % 10 == 0 and batch_idx == 0:\n",
    "            original_slice = x[0, 0, :, :, 128].detach().cpu().numpy()  # Select a single slice from the 3D volume\n",
    "            #reconstruction_slice = self.unet(x[0].unsqueeze(0))[0, 0, :, :, 128].detach().cpu().numpy()  # Select a single slice from the 3D reconstruction\n",
    "            reconstruction_slice = np.argmax(x_hat[0,:,:,:,128], axis=0)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(original_slice, cmap='gray')\n",
    "            plt.title('Original Val Slice')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(reconstruction_slice, cmap='gray')\n",
    "            plt.title('Reconstructed Val Slice')\n",
    "            plt.show()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# Define dataset and data loaders for both training and validation sets\n",
    "train_data_dir = \"./images/TrainFullLabels70\"\n",
    "val_data_dir = \"./images/ValFullLabels30\"\n",
    "\n",
    "transform = Compose([\n",
    "    Lambda(func=lambda x: np.expand_dims(x, 0) if x.ndim == 3 else x),\n",
    "    RandSpatialCrop((256, 256, 256), random_size=False),\n",
    "    RandRotate90(prob=0.5),\n",
    "    ToTensor(dtype=torch.float32)\n",
    "])\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.files = [f for f in os.listdir(data_dir) if f.endswith('.nrrd')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.data_dir, self.files[idx])\n",
    "        data, header = nrrd.read(file_path)\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data, data\n",
    "\n",
    "train_dataset = MyDataset(train_data_dir, transform)\n",
    "val_dataset = MyDataset(val_data_dir, transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# Define a custom callback to plot both training and validation losses\n",
    "\n",
    "class PlotLossCallback(pl.Callback):\n",
    "    def __init__(self, log_dir):\n",
    "        super().__init__()\n",
    "        self.log_dir = log_dir\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        # Clear previous graphs\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        self.writer = SummaryWriter(self.log_dir)\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module, **kwargs):\n",
    "        epoch = trainer.current_epoch\n",
    "        train_loss = trainer.callback_metrics['train_loss'].cpu().item()\n",
    "        val_loss = trainer.callback_metrics['val_loss'].cpu().item()\n",
    "\n",
    "        # Write both training and validation loss to the same graph with epoch as global step\n",
    "        self.writer.add_scalars('1 Channel Loss', {'training' : train_loss,\n",
    "                                                                'validation' : val_loss }, global_step=epoch +1 )\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        self.writer.close()\n",
    "\n",
    "#early_stop_callback = pl.callbacks.EarlyStopping(monitor='val_loss', patience=80)\n",
    "#getting rid of early stop callback for now \n",
    "# Define Lightning trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1500,\n",
    "    callbacks=[PlotLossCallback(\"./logs/\")],\n",
    "    profiler='simple')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and start training\n",
    "model = AutoEncoder()\n",
    "trainer.fit(model, train_dataloader, val_dataloader)\n",
    "torch.save(model.state_dict(), \"./images/Model/model_64channel_80patience.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in model \n",
    "model = AutoEncoder()\n",
    "model.load_state_dict(torch.load(\"./images/Model/model_1channel.pth\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2factor downsample 3d image graphing\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "test_dir = \"./images/3dTest\"\n",
    "test_data = MyDataset(test_dir, transform)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Define the color map\n",
    "color_map = np.array([\n",
    "    [0, 0, 0, 0],      # Transparent for background (0)\n",
    "    [255, 0, 0, 255],  # Red for arteries (1)\n",
    "    [0, 0, 255, 255]   # Blue for veins (2)\n",
    "], dtype=np.uint8)\n",
    "\n",
    "# Downsampling factor\n",
    "downsample_factor = 2\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, _) in enumerate(test_dataloader):\n",
    "        x_hat = model(x)\n",
    "        \n",
    "        # Reconstruct and display the whole volume from the first test image\n",
    "        original_volume = x[0, 0, :, :, :].detach().cpu().numpy().astype(int)  \n",
    "\n",
    "        # Downsample original volume\n",
    "        original_volume_downsampled = original_volume[::downsample_factor, ::downsample_factor, ::downsample_factor]\n",
    "\n",
    "        reconstruction_volume = np.argmax(x_hat[0,:,:,:,:], axis=0)\n",
    "\n",
    "        # Downsample reconstructed volume\n",
    "        reconstruction_volume_downsampled = reconstruction_volume[::downsample_factor, ::downsample_factor, ::downsample_factor]\n",
    "\n",
    "        # Downsample color map along the first axis to match the number of unique values in the downsampled volume\n",
    "        color_map_downsampled = color_map[:len(np.unique(original_volume_downsampled))]\n",
    "\n",
    "        # Plot original and reconstructed volumes with titles using Matplotlib\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Plot original volume with assigned colors and no edge color\n",
    "        ax1 = fig.add_subplot(121, projection='3d')\n",
    "        ax1.set_title('Original Volume')\n",
    "\n",
    "        # Define colors for each voxel value in the original volume using the downsampled color map\n",
    "        original_colors = np.take(color_map_downsampled, original_volume_downsampled, axis=0) / 255.0\n",
    "        ax1.voxels(original_volume_downsampled, facecolors=original_colors)\n",
    "\n",
    "        # Plot reconstructed volume with assigned colors and no edge color\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "        ax2.set_title('Reconstructed Volume')\n",
    "\n",
    "        # Define colors for each voxel value in the reconstructed volume using the downsampled color map\n",
    "        reconstruction_colors = np.take(color_map_downsampled, reconstruction_volume_downsampled, axis=0) / 255.0\n",
    "        ax2.voxels(reconstruction_volume_downsampled, facecolors=reconstruction_colors)\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing model\n",
    "\n",
    "test_dir = \"./images/Test\"\n",
    "test_data = MyDataset(test_dir, transform)\n",
    "test_dataloader = DataLoader(test_data, batch_size = 1, shuffle= False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x,_) in enumerate(test_dataloader):\n",
    "        x_hat = model(x)\n",
    "        \n",
    "        # Reconstruct and display a single slice from the first test image\n",
    "        original_slice = x[0, 0, :, :, 128].detach().cpu().numpy() \n",
    "        reconstruction_slice = np.argmax(x_hat[0,:,:,:,128], axis=0)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_slice, cmap='gray')\n",
    "        plt.title('Original Test Slice')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(reconstruction_slice, cmap='gray')\n",
    "        plt.title('Reconstructed Test Slice')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
